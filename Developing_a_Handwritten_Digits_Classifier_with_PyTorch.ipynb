{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ef384a90",
      "metadata": {
        "id": "ef384a90"
      },
      "source": [
        "# Step 1: Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65022b8",
      "metadata": {
        "id": "b65022b8"
      },
      "source": [
        "\n",
        "## 1.1 Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8d2956b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d2956b1",
        "outputId": "9f35b9b4-dd00-4d03-ea12-7f2d8b9623f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.2.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install --user torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "74408b78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74408b78",
        "outputId": "cdf6e8e1-5959-4cff-d442-2f309d281f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 17350547.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 480916.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4407864.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3535076.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Converts the image to a PyTorch tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalizes the tensor\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "994a8504",
      "metadata": {
        "id": "994a8504"
      },
      "source": [
        "### Transforms:\n",
        "* ToTensor(): Converts the image from a PIL Image or numpy array to a PyTorch tensor.\n",
        "\n",
        "* Normalize(mean, std): Normalizes the image tensor with the given mean and standard deviation. This standardization helps in speeding up the training and achieving better convergence by ensuring that the input data has a mean of 0 and a standard deviation of 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4985503e",
      "metadata": {
        "id": "4985503e"
      },
      "source": [
        "## 1.2 Create DataLoader\n",
        "* DataLoader is used to load the dataset in batches, which makes the training process more efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0a0d5640",
      "metadata": {
        "id": "0a0d5640"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
        "# No Validation Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d0c219",
      "metadata": {
        "id": "72d0c219"
      },
      "source": [
        "### DataLoader:\n",
        "* train_loader: Loads the training data in batches of 64 images and shuffles them to ensure that the model doesn't learn the order of the data.\n",
        "\n",
        "* test_loader: Loads the test data in batches of 1000 images for evaluation purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fd8f25b",
      "metadata": {
        "id": "7fd8f25b"
      },
      "source": [
        "# Step 2: Data Visualization and Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cad05f63",
      "metadata": {
        "id": "cad05f63"
      },
      "source": [
        "## 2.1 Visualize the Dataset\n",
        "* Visualizing the data helps in understanding what the input images look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0409bced",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "0409bced",
        "outputId": "f0fd913f-0fda-49ec-ae0f-dc9a6f1f4109"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.tight_layout()\n",
        "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "    plt.title(f\"Ground Truth: {example_targets[i]}\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7ed9c81",
      "metadata": {
        "id": "f7ed9c81"
      },
      "source": [
        "### Visualization:\n",
        "* We take a batch of images from the train_loader.\n",
        "* Plot the first 6 images in a 2x3 grid using Matplotlib.\n",
        "* 1This gives a visual confirmation that our data is loaded and preprocessed correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3b6dd7c",
      "metadata": {
        "id": "e3b6dd7c"
      },
      "source": [
        "## 2.2 Explore Data Size and Shape\n",
        "\n",
        "* Exploring the size and shape ensures that the data matches the expected input dimensions for the neural network.\n",
        "* This prints the shape of a batch of images, which should be (64, 1, 28, 28) for the training loader, indicating 64 images of size 28x28 pixels with 1 color channel (grayscale)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2fda5bc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fda5bc9",
        "outputId": "5de61f26-adca-4b1f-c840-c02098bd4b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "print(example_data.shape) # Should output (batch_size, 1, 28, 28)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9327e08",
      "metadata": {
        "id": "b9327e08"
      },
      "source": [
        "# Step 3: Building and Training the Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb2461e",
      "metadata": {
        "id": "1fb2461e"
      },
      "source": [
        "## 3.1 Build the Neural Network\n",
        "* We define a simple fully connected neural network (also called a feedforward neural network)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b9fb3b6c",
      "metadata": {
        "id": "b9fb3b6c"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
        "        x = F.relu(self.fc1(x))  # First fully connected layer\n",
        "        x = F.relu(self.fc2(x))  # Second fully connected layer\n",
        "        x = self.fc3(x)  # Output layer\n",
        "        return F.log_softmax(x, dim=1)  # Apply log softmax for output probabilities\n",
        "\n",
        "model = Net()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f1de6d5",
      "metadata": {
        "id": "9f1de6d5"
      },
      "source": [
        "### Network Layers:\n",
        "\n",
        "* fc1: First fully connected layer with 128 neurons.\n",
        "* fc2: Second fully connected layer with 64 neurons.\n",
        "* fc3: Output layer with 10 neurons (one for each digit 0-9).\n",
        "\n",
        "### Forward Method:\n",
        "\n",
        "* Flattens the 28x28 image to a 784-element vector.\n",
        "* Applies ReLU activation after each of the first two layers.\n",
        "* Outputs the log probabilities using log_softmax."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb40698",
      "metadata": {
        "id": "7bb40698"
      },
      "source": [
        "## 3.2 Create an Optimizer\n",
        "* An optimizer is used to update the weights of the network based on the computed gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f6a2052c",
      "metadata": {
        "id": "f6a2052c"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08eeadd5",
      "metadata": {
        "id": "08eeadd5"
      },
      "source": [
        "* Adam Optimizer: An adaptive learning rate optimization algorithm that's popular for its efficiency and performance. The learning rate is set to 0.001."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e9fe9e",
      "metadata": {
        "id": "24e9fe9e"
      },
      "source": [
        "## 3.3 Train the Network\n",
        "* The training loop processes each batch of training data, computes the loss, performs backpropagation, and updates the weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a10d2ab8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a10d2ab8",
        "outputId": "ec57e01f-3d1d-4783-8801-0213edb41991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.005339\tAccuracy: 100.0000%\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.045465\tAccuracy: 99.5204%\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.082486\tAccuracy: 99.4403%\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.028481\tAccuracy: 99.4549%\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.072760\tAccuracy: 99.4350%\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.010473\tAccuracy: 99.3700%\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.003034\tAccuracy: 99.3942%\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.004092\tAccuracy: 99.3915%\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.003496\tAccuracy: 99.3933%\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.005447\tAccuracy: 99.3878%\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.012041\tAccuracy: 100.0000%\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.016843\tAccuracy: 99.5668%\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.035689\tAccuracy: 99.5258%\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.067402\tAccuracy: 99.5224%\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.003703\tAccuracy: 99.4935%\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.011672\tAccuracy: 99.4168%\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.023181\tAccuracy: 99.3188%\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.027299\tAccuracy: 99.2979%\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.020229\tAccuracy: 99.2821%\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.021210\tAccuracy: 99.2820%\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.001140\tAccuracy: 100.0000%\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.002499\tAccuracy: 99.5050%\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.000864\tAccuracy: 99.5414%\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.000781\tAccuracy: 99.5691%\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.104057\tAccuracy: 99.4623%\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.018976\tAccuracy: 99.4417%\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.003011\tAccuracy: 99.3474%\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.053138\tAccuracy: 99.3402%\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.052731\tAccuracy: 99.2880%\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.003340\tAccuracy: 99.2838%\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.001369\tAccuracy: 100.0000%\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.038802\tAccuracy: 99.5823%\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000463\tAccuracy: 99.7046%\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.015968\tAccuracy: 99.6937%\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.009926\tAccuracy: 99.6922%\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.000209\tAccuracy: 99.7224%\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.030680\tAccuracy: 99.7114%\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.061877\tAccuracy: 99.6545%\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.001396\tAccuracy: 99.5943%\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.008708\tAccuracy: 99.5543%\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.012198\tAccuracy: 100.0000%\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.000554\tAccuracy: 99.3038%\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.004681\tAccuracy: 99.5025%\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.038984\tAccuracy: 99.5743%\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.003293\tAccuracy: 99.5441%\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.028565\tAccuracy: 99.5072%\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.016117\tAccuracy: 99.4826%\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.002591\tAccuracy: 99.4584%\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.000082\tAccuracy: 99.4460%\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.028609\tAccuracy: 99.4503%\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.013347\tAccuracy: 100.0000%\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.002561\tAccuracy: 99.5823%\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.006354\tAccuracy: 99.5569%\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.001023\tAccuracy: 99.4653%\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.000136\tAccuracy: 99.4935%\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.002808\tAccuracy: 99.5072%\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.006186\tAccuracy: 99.5086%\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000760\tAccuracy: 99.4829%\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.001107\tAccuracy: 99.4441%\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.001090\tAccuracy: 99.4537%\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.007612\tAccuracy: 100.0000%\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.002332\tAccuracy: 99.6597%\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.008008\tAccuracy: 99.6657%\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.011618\tAccuracy: 99.6522%\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.066597\tAccuracy: 99.6259%\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.017009\tAccuracy: 99.5259%\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.018712\tAccuracy: 99.5138%\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.004205\tAccuracy: 99.4985%\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000621\tAccuracy: 99.4967%\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.001431\tAccuracy: 99.4815%\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.002667\tAccuracy: 100.0000%\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.005314\tAccuracy: 99.7061%\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.003146\tAccuracy: 99.7901%\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.005385\tAccuracy: 99.8183%\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000063\tAccuracy: 99.7818%\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.001146\tAccuracy: 99.7723%\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.026012\tAccuracy: 99.7556%\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.000239\tAccuracy: 99.7035%\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.000848\tAccuracy: 99.6411%\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.012603\tAccuracy: 99.5994%\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.001183\tAccuracy: 100.0000%\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.025753\tAccuracy: 99.7061%\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000500\tAccuracy: 99.6813%\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.001525\tAccuracy: 99.6833%\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.004174\tAccuracy: 99.7350%\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000918\tAccuracy: 99.7318%\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000759\tAccuracy: 99.7140%\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000272\tAccuracy: 99.6879%\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.046788\tAccuracy: 99.6567%\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.005381\tAccuracy: 99.6306%\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.059808\tAccuracy: 98.4375%\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000445\tAccuracy: 99.6287%\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.004089\tAccuracy: 99.6035%\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000279\tAccuracy: 99.6262%\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000966\tAccuracy: 99.6454%\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.095736\tAccuracy: 99.5977%\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.011147\tAccuracy: 99.5710%\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000248\tAccuracy: 99.5698%\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.005669\tAccuracy: 99.5552%\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.009905\tAccuracy: 99.5387%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            accuracy = 100. * correct / total\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82f30820",
      "metadata": {
        "id": "82f30820"
      },
      "source": [
        "### Training Loop:\n",
        "* For each epoch, the model is set to training mode.\n",
        "* For each batch, gradients are reset, forward pass is performed, loss is computed, backpropagation is done, and optimizer updates the weights.\n",
        "* The loss is printed every 100 batches for monitoring progress."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e29a4e43",
      "metadata": {
        "id": "e29a4e43"
      },
      "source": [
        "## Step 4: Model Evaluation and Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6812bfa4",
      "metadata": {
        "id": "6812bfa4"
      },
      "source": [
        "### 4.1 Evaluate the Network\n",
        "* After training, we evaluate the network on the test dataset to see how well it performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fe7a5ff4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe7a5ff4",
        "outputId": "982f36c0-df6a-4d8d-b087-b1fe15f0e41e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1403, Accuracy: 9748/10000 (97%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46be17a0",
      "metadata": {
        "id": "46be17a0"
      },
      "source": [
        "### Evaluation:\n",
        "* The model is set to evaluation mode.\n",
        "* The test data is processed without computing gradients (no_grad()), reducing memory usage and speeding up computations.\n",
        "* The total loss and number of correct predictions are accumulated.\n",
        "* The average loss and accuracy are calculated and printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3380db2a",
      "metadata": {
        "id": "3380db2a"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'mnist_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PkYLPf6_kTEQ",
      "metadata": {
        "id": "PkYLPf6_kTEQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
